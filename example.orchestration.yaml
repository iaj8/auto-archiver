steps:
  # only 1 feeder allowed
  feeder: gsheet_feeder # defaults to cli_feeder
  archivers: # order matters, uncomment to activate
    - vk_archiver
    - telethon_archiver
    - telegram_archiver
    - twitter_archiver
    - twitter_api_archiver
    # - instagram_api_archiver
    - instagram_archiver
    - instagram_tbot_archiver
    - tiktok_archiver
    - youtubedl_archiver
    # - wayback_archiver_enricher
    # - wacz_archiver_enricher
  enrichers:
    - hash_enricher
    - metadata_enricher
    - screenshot_enricher
    - thumbnail_enricher
    # - wayback_archiver_enricher
    # - wacz_archiver_enricher
    # - pdq_hash_enricher # if you want to calculate hashes for thumbnails, include this after thumbnail_enricher
  formatter: html_formatter # choose from mute_formatter, html_formatter, gsheet_formatter
  storages:
    # - local_storage
    # - s3_storage
    # - gdrive_storage
    - gcs_storage
  databases:
    - console_db
    # - csv_db
    - gsheet_db
    # - mongo_db

configurations:
  gsheet_feeder:
    sheet: "AutoArchiver Test Sheet for VI"
    header: 1
    service_account: "secrets/service_account.json"
    # allow_worksheets: "only parse this worksheet"
    # block_worksheets: "blocked sheet 1,blocked sheet 2"
    use_sheet_names_in_stored_paths: false
    columns:
      url: link
      status: media number + archive status
      # folder: destination folder
      archive: additional information
      archived_filenames: archived file location(s)
      downloaded_filenames: original downloaded filename(s)
      date: archive date
      thumbnail: media screenshot
      timestamp: upload timestamp
      timestamp_est: upload timestamp est
      title: upload title
      title_translated: upload title translated
      text: text of post
      text_translated: text of post translated
      screenshot: post screenshot link
      hash: hash
      # pdq_hash: perceptual hashes
      # wacz: wacz
      # replaywebpage: replaywebpage

  instagram_tbot_archiver:
    api_id: "24045990"
    api_hash: "7b17a3eaa7742009e4815cefa5476604"
    session_file: "secrets/instabot-2024-07-26693cd8cb"

  telethon_archiver:
    api_id: "24045990"
    api_hash: "7b17a3eaa7742009e4815cefa5476604"
    session_file: "secrets/telethon-2024-07-26a2fed7f3"
    join_channels: false
    channel_invites: # if you want to archive from private channels
      - invite: https://t.me/+123456789
        id: 0000000001
      - invite: https://t.me/+123456788
        id: 0000000002

  twitter_api_archiver:
    netscape_cookies: "secrets/netscape_cookies.txt"
    # either bearer_token only
    bearer_token: "AAAAAAAAAAAAAAAAAAAAAESRrAEAAAAAmC4S38zyRV6yPwH5JRfAfxx1ggc%3Dc2FAKDDo1rW4LD7erMjHw9J9Q3xt8ag36dGx69sUF6Tb8agi2F"
    # OR all of the below
    # consumer_key: ""
    # consumer_secret: ""
    # access_token: ""
    # access_secret: ""

  twitter_archiver:
    netscape_cookies: "secrets/netscape_cookies.txt"

  instagram_archiver:
    username: "jhaveriishaan94"
    password: "Igordimov109"
    session_file: "secrets/instaloader.session"

  vk_archiver:
    username: "+13478803642"
    password: "Igordimov109"
    session_file: "secrets/vk_config.v2.json"

  youtubedl_archiver:
    netscape_cookies: "secrets/netscape_cookies.txt"

  screenshot_enricher:
    width: 1280
    height: 1280

  wayback_archiver_enricher:
    timeout: 10
    key: "wayback key"
    secret: "wayback secret"

  hash_enricher:
    algorithm: "SHA3-512" # can also be SHA-256

  wacz_archiver_enricher:
    profile: secrets/profile.tar.gz

  local_storage:
    save_to: "/Users/ishaanjhaveri/Desktop/auto_archiver_test_local_archive"
    save_absolute: true
    filename_generator: static
    path_generator: flat

  s3_storage:
    bucket: your-bucket-name
    region: reg1
    key: S3_KEY
    secret: S3_SECRET
    endpoint_url: "https://{region}.digitaloceanspaces.com"
    cdn_url: "https://{bucket}.{region}.cdn.digitaloceanspaces.com/{key}"
    # if private:true S3 urls will not be readable online
    private: false
    # with 'random' you can generate a random UUID for the URL instead of a predictable path, useful to still have public but unlisted files, alternative is 'default' or not omitted from config
    key_path: random

  gcs_storage:
    bucket_name: vi_workflow
    top_level_folder: vi_workflow_tests
    service_account: "secrets/service_account.json"
    scopes: ['https://www.googleapis.com/auth/cloud-platform']
    cdn_url: "https://storage.googleapis.com/{bucket_name}/{key}"

  gdrive_storage:
    path_generator: url
    filename_generator: static
    root_folder_id: 1ekMiHv15Zg85lRNESD014dGWym-zAq-4
    oauth_token: secrets/gd-token.json # needs to be generated with scripts/create_update_gdrive_oauth_token.py
    service_account: "secrets/service_account.json"

  csv_db:
    csv_file: "./local_archive/db.csv"
  
  gsheet_db:
    service_account: "secrets/service_account.json"